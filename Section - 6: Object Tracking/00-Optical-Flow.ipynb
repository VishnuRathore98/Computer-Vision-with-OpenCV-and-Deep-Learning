{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "\n",
    "----\n",
    "#### NOTE: It is probably a good idea to restart the kernel if you ever run these cells, as the tracking algo can sometimes get caught in a loop with your camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ShiTomasi corner detection (good features to track paper)\n",
    "corner_track_params = dict(maxCorners = 10,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for Lucas Kanade Optical Flow\n",
    "\n",
    "Detect the motion of specific points or the aggregated motion of regions by modifying the winSize argument. This determines the integration window size. Small windows are more sensitive to noise and may miss larger motions. Large windows will “survive” an occlusion.\n",
    "\n",
    "The integration appears smoother with the larger window size.\n",
    "\n",
    "criteria has two here - the max number (10 above) of iterations and epsilon (0.03 above). More iterations means a more exhaustive search, and a smaller epsilon finishes earlier. These are primarily useful in exchanging speed vs accuracy, but mainly stay the same.\n",
    "\n",
    "When maxLevel is 0, it is the same algorithm without using pyramids (ie, calcOpticalFlowLK). Pyramids allow finding optical flow at various resolutions of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (200,200),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10,0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Grab the very first frame of the stream\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Grab a grayscale image (We will refer to this as the previous frame)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Grabbing the corners\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask = None, **corner_track_params)\n",
    "\n",
    "# Create a matching mask of the previous frame for drawing on later\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Grab current frame\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # Grab gray scale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the Optical Flow on the Gray Scale Frame\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "    \n",
    "    # Using the returned status array (the status output)\n",
    "    # status output status vector (of unsigned chars); each element of the vector is set to 1 if\n",
    "    # the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1]\n",
    "    \n",
    "    # Use ravel to get points to draw lines and circles\n",
    "    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        \n",
    "        x_new,y_new = new.ravel()\n",
    "        x_prev,y_prev = prev.ravel()\n",
    "        \n",
    "        # Lines will be drawn using the mask created from the first frame\n",
    "        mask = cv2.line(mask, (x_new,y_new),(x_prev,y_prev), (0,255,0), 3)\n",
    "        \n",
    "        # Draw red circles at corner points\n",
    "        frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1)\n",
    "    \n",
    "    # Display the image along with the mask we drew the line on.\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "    # Now update the previous frame and previous points\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed Explanation of Optical Flow Code\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Shi-Tomasi Corner Detection**\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask=None, **corner_track_params)\n",
    "```\n",
    "\n",
    "- **Concept**:  \n",
    "  Shi-Tomasi is a corner detection algorithm that finds \"good features to track.\" Corners are points in the image where the intensity changes significantly in both directions (horizontal and vertical), making them easy to identify across frames.\n",
    "\n",
    "- **Why Corners?**  \n",
    "  - Corners are more stable and easier to track compared to flat regions or edges:\n",
    "    - A flat region (e.g., plain wall) looks similar in all directions, making it hard to track.\n",
    "    - An edge only has a change in one direction, so it’s less distinctive.\n",
    "    - A corner has a unique intensity change in all directions.\n",
    "\n",
    "- **Parameters Explained**:\n",
    "  - `maxCorners`: Limits the number of corners detected (e.g., 10 corners).\n",
    "  - `qualityLevel`: A threshold to discard weak corners. It’s a fraction of the strongest corner's quality. Higher values result in fewer, but stronger corners.\n",
    "  - `minDistance`: Ensures corners are not too close together.\n",
    "  - `blockSize`: Size of the window used to calculate the intensity gradient.\n",
    "\n",
    "- **How it Works**:\n",
    "  1. Computes the gradient (intensity change) in the image.\n",
    "  2. Looks for pixels where the gradient is strong in both directions.\n",
    "  3. Applies the `qualityLevel` and `minDistance` filters.\n",
    "\n",
    "- **Example Output**:  \n",
    "  An array of corner points, each with \\((x, y)\\) coordinates. These points will be used for tracking in the next frame.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Lucas-Kanade Optical Flow**\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "```\n",
    "\n",
    "- **Concept**:  \n",
    "  The Lucas-Kanade (LK) method tracks points across frames. It assumes that:\n",
    "  1. The motion between two frames is small.\n",
    "  2. Nearby points move in a similar way.\n",
    "\n",
    "  The algorithm finds the new position of each corner point in the next frame.\n",
    "\n",
    "- **How It Works**:\n",
    "  1. A small window (defined by `winSize`) is placed around each point to track.\n",
    "  2. The algorithm looks for the most similar region in the next frame by comparing brightness patterns inside the window.\n",
    "  3. It iteratively adjusts the position until the difference is minimized (controlled by `criteria`).\n",
    "\n",
    "- **Parameters Explained**:\n",
    "  - `prev_gray`: Previous frame (grayscale).\n",
    "  - `frame_gray`: Current frame (grayscale).\n",
    "  - `prevPts`: Points to track in the previous frame.\n",
    "  - `winSize`: Size of the search window for matching points.\n",
    "  - `maxLevel`: Number of image pyramid levels for multi-scale tracking. Higher levels allow tracking across varying sizes (e.g., zoomed-in/out objects).\n",
    "  - `criteria`: Stopping conditions for iterations:\n",
    "    - `TERM_CRITERIA_EPS`: Stops when the positional change is small (e.g., < 0.03).\n",
    "    - `TERM_CRITERIA_COUNT`: Stops after a fixed number of iterations (e.g., 10).\n",
    "\n",
    "- **Outputs**:\n",
    "  - `nextPts`: Estimated new positions of the points in the current frame.\n",
    "  - `status`: A binary array where `1` means the point was successfully tracked, and `0` means it wasn’t.\n",
    "  - `err`: Error values indicating how well the point was tracked.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Tracking Points Across Frames**\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "good_new = nextPts[status == 1]\n",
    "good_prev = prevPts[status == 1]\n",
    "```\n",
    "\n",
    "- **Concept**:  \n",
    "  Not all points are successfully tracked between frames.  \n",
    "  - `status == 1` filters only the points that were successfully tracked.  \n",
    "    - `good_prev`: The positions of the tracked points in the previous frame.  \n",
    "    - `good_new`: The positions of the same points in the current frame.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Drawing the Motion**\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "for i, (new, prev) in enumerate(zip(good_new, good_prev)):\n",
    "    x_new, y_new = new.ravel()\n",
    "    x_prev, y_prev = prev.ravel()\n",
    "    mask = cv2.line(mask, (x_new, y_new), (x_prev, y_prev), (0, 255, 0), 3)\n",
    "    frame = cv2.circle(frame, (x_new, y_new), 8, (0, 0, 255), -1)\n",
    "```\n",
    "\n",
    "- **What It Does**:\n",
    "  - Loops through each pair of points (previous and current positions).\n",
    "  - Draws a **line** on the `mask` from the previous position to the current position to represent motion.\n",
    "  - Draws a **red circle** on the `frame` at the current position.\n",
    "\n",
    "- **Key Details**:\n",
    "  - `zip(good_new, good_prev)`: Combines the current and previous points so they can be processed together.\n",
    "  - `ravel()`: Flattens the \\((x, y)\\) coordinates into simple numbers for easier drawing.\n",
    "  - `cv2.line`: Draws the green motion line on the mask.\n",
    "    - `(0, 255, 0)`: Green color.\n",
    "    - `3`: Thickness of the line.\n",
    "  - `cv2.circle`: Draws a red dot at the new position of the point.\n",
    "    - `(0, 0, 255)`: Red color.\n",
    "    - `-1`: Fills the circle.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Combining Mask and Frame**\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "img = cv2.add(frame, mask)\n",
    "cv2.imshow('frame', img)\n",
    "```\n",
    "\n",
    "- **Concept**:  \n",
    "  Combines the motion lines (on `mask`) with the current frame (`frame`) and displays the result:\n",
    "  - `cv2.add`: Adds the two images together.\n",
    "  - `cv2.imshow`: Displays the combined image in a window called `'frame'`.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Loop Control and Update**\n",
    "\n",
    "### Key Updates:\n",
    "```python\n",
    "k = cv2.waitKey(30) & 0xff\n",
    "if k == 27:\n",
    "    break\n",
    "```\n",
    "\n",
    "- **`cv2.waitKey`**: Waits for 30 ms to check if a key is pressed.  \n",
    "  - `27`: ASCII code for the `Esc` key. If pressed, the loop exits.\n",
    "\n",
    "### Updating Variables:\n",
    "```python\n",
    "prev_gray = frame_gray.copy()\n",
    "prevPts = good_new.reshape(-1, 1, 2)\n",
    "```\n",
    "\n",
    "- **Why Update?**  \n",
    "  To track motion, the current frame becomes the new \"previous frame\" for the next iteration.\n",
    "  - `prev_gray`: The current grayscale frame is stored as the previous frame.\n",
    "  - `prevPts`: The new points (`good_new`) are reshaped into the format required for tracking in the next loop.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Cleanup**\n",
    "\n",
    "### Code:\n",
    "```python\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "```\n",
    "\n",
    "- **Purpose**:\n",
    "  - `cv2.destroyAllWindows()`: Closes all OpenCV windows.\n",
    "  - `cap.release()`: Releases the video capture resource, freeing up the camera for other applications.\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary of Workflow**\n",
    "1. Detect key points (corners) in the first frame.\n",
    "2. Continuously read new frames and convert them to grayscale.\n",
    "3. Use the Lucas-Kanade method to track the motion of these key points.\n",
    "4. Draw lines and circles to visualize the motion.\n",
    "5. Update frames and points to repeat the process.\n",
    "6. Exit and clean up resources when the user presses the `Esc` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
